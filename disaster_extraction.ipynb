{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from disaster_extr_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'data/emdat_processed.csv'\n",
    "parse_dates = ['StartDate', 'EndDate']\n",
    "df_emdat = pd.read_csv(data, index_col=\"Dis No\", parse_dates = parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "australia_heat_wave = { \n",
    "    'Group': 'Natural',\n",
    "    'Subgroup':'Meteorological', \n",
    "    'Type':'Extreme temperature ', \n",
    "    'Subtype':'Heat wave', \n",
    "    'Subsubtype': 'NaN',\n",
    "    'Name':'NaN', \n",
    "    'Country':'Australia', \n",
    "    'ISO':'AUS', \n",
    "    'Region': 'Australia and New Zealand',\n",
    "    'Continent': 'Oceania',\n",
    "    'Origin':'NaN', \n",
    "    'Magnitude':48.2, \n",
    "    'Scale':'°C', \n",
    "    'Deaths': 0,\n",
    "    'Injured':0, \n",
    "    'Affected':0,\n",
    "    'Homeless':0,\n",
    "    'TotalAffected':0, \n",
    "    'Damages':0, \n",
    "    'StartDate':'2017-01-30', \n",
    "    'EndDate': '2017-02-14',\n",
    "    'Duration':15\n",
    "}\n",
    "# Not necessary, row already added to csv file\n",
    "#row_series = pd.Series(data=australia_heat_wave, name='2017-9999-AUS')\n",
    "#df_emdat = df_emdat.append(row_series, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group                              Natural\n",
       "Subgroup                    Meteorological\n",
       "Type                  Extreme temperature \n",
       "Subtype                          Heat wave\n",
       "Subsubtype                             NaN\n",
       "Name                                   NaN\n",
       "Country                          Australia\n",
       "ISO                                    AUS\n",
       "Region           Australia and New Zealand\n",
       "Continent                          Oceania\n",
       "Origin                                 NaN\n",
       "Magnitude                             48.2\n",
       "Scale                                   °C\n",
       "Deaths                                 0.0\n",
       "Injured                                0.0\n",
       "Affected                               0.0\n",
       "Homeless                               0.0\n",
       "TotalAffected                          0.0\n",
       "Damages                                0.0\n",
       "StartDate              2017-01-30 00:00:00\n",
       "EndDate                2017-02-14 00:00:00\n",
       "Duration                                15\n",
       "Name: 2017-9999-AUS, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emdat.loc['2017-9999-AUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORMS = {\n",
    "    '2015': ['2015-0470-MEX'],\n",
    "    '2016': ['2016-0041-FJI'],\n",
    "    '2017': ['2017-0362-USA'],\n",
    "    '2018': ['2018-0342-USA', '2018-0341-CHN', '2018-0341-PHL', '2018-0341-HKG'], # two separate storms over same time period\n",
    "    '2019': ['2019-0492-JPN'],\n",
    "    #'2020': ['2020-0211-LKA', '2020-0211-BGD', '2020-0211-IND'] # can't use because in May 2020\n",
    "}\n",
    "\n",
    "STORMS_val = {\n",
    "    '2018-0341-CHN': {'Magnitude': 240},\n",
    "    '2018-0342-USA': {'Magnitude': 240, 'Damages': 24000000},\n",
    "    #'2020-0211-BGD': {'Magnitude': 151},\n",
    "    #'2020-0211-LKA': {'Magnitude': 80},\n",
    "    '2018-0341-PHL': {'Deaths': 127, 'Damages': 628000},\n",
    "    '2018-0341-CHN': {'Deaths': 6, 'Damages': 1990000},\n",
    "    '2018-0341-HKG': {'Damages': 930000},\n",
    "    '2017-0362-USA': {'Deaths': 106, 'Damages': 125000000},\n",
    "    '2016-0041-FJI': {'Damages': 1400000},\n",
    "    '2015-0470-MEX': {'Magnitude': 345, 'Damages': 462000}\n",
    "}\n",
    "\n",
    "STORMS_2020 = {\n",
    "    '2020': ['2019-0573-PHL']\n",
    "}\n",
    "\n",
    "STORMS_2020_val = {}\n",
    "\n",
    "HEAT_WAVES = {\n",
    "    '2015': ['2015-0189-IND'],\n",
    "    '2016': ['2016-0133-IND'],\n",
    "    '2017': ['2017-9999-AUS', '2017-0072-AUS'], # heat wave and associated fire\n",
    "    '2018': ['2018-0226-JPN', '2018-0256-PRK'],\n",
    "    '2019': ['2019-0366-BEL', '2019-0366-FRA', '2019-0366-NLD', '2019-0366-DEU'], #'2019-0366-AUT' (no value for temp), '2019-0650-GBR' (lasts too long)\n",
    "  #  '2020': ['2019-0545-AUS'] # Forest fire (can't use '2020-0441-USA' because in august)\n",
    "}\n",
    "\n",
    "HEAT_WAVES_2020 = {\n",
    "    '2020': ['2019-0545-AUS'] # Forest fire (can't use '2020-0441-USA' because in august)\n",
    "}\n",
    "HEAT_WAVES_2020_val = {\n",
    "    #'2020-0441-USA': {'Magnitude': 4180},\n",
    "    '2019-0545-AUS': {'Magnitude': 186360}\n",
    "}\n",
    "\n",
    "HEAT_WAVES_val = {\n",
    "    #'2020-0441-USA': {'Magnitude': 4180},\n",
    "    '2017-0072-AUS': {'Magnitude': 550},\n",
    "    '2018-0256-PRK': {'Deaths': 42},\n",
    "    #'2019-0545-AUS': {'Magnitude': 186360}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heat = get_df_disaster(df_emdat, HEAT_WAVES, HEAT_WAVES_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Name</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Damages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dis No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-0189-IND</th>\n",
       "      <td>48.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-0133-IND</th>\n",
       "      <td>51.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-9999-AUS</th>\n",
       "      <td>48.2</td>\n",
       "      <td>°C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-0072-AUS</th>\n",
       "      <td>550.0</td>\n",
       "      <td>Km2</td>\n",
       "      <td>Sir Ivan fire</td>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-0226-JPN</th>\n",
       "      <td>41.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>2018-07-15</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-0256-PRK</th>\n",
       "      <td>38.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-0366-BEL</th>\n",
       "      <td>41.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-0366-FRA</th>\n",
       "      <td>44.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>868.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-0366-NLD</th>\n",
       "      <td>40.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-0366-DEU</th>\n",
       "      <td>42.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Magnitude Scale           Name  StartDate    EndDate  Deaths  \\\n",
       "Dis No                                                                        \n",
       "2015-0189-IND       48.0    °C            NaN 2015-05-20 2015-05-31  2248.0   \n",
       "2016-0133-IND       51.0    °C            NaN 2016-04-01 2016-05-20   300.0   \n",
       "2017-9999-AUS       48.2    °C            NaN 2017-01-30 2017-02-14     0.0   \n",
       "2017-0072-AUS      550.0   Km2  Sir Ivan fire 2017-02-09 2017-02-13     0.0   \n",
       "2018-0226-JPN       41.0    °C            NaN 2018-07-01 2018-07-15   119.0   \n",
       "2018-0256-PRK       38.0    °C            NaN 2018-07-11 2018-08-03    42.0   \n",
       "2019-0366-BEL       41.0    °C            NaN 2019-07-19 2019-07-27   400.0   \n",
       "2019-0366-FRA       44.0    °C            NaN 2019-07-21 2019-07-27   868.0   \n",
       "2019-0366-NLD       40.0    °C            NaN 2019-07-22 2019-07-27   400.0   \n",
       "2019-0366-DEU       42.0    °C            NaN 2019-07-24 2019-07-25     0.0   \n",
       "\n",
       "               Damages  \n",
       "Dis No                  \n",
       "2015-0189-IND      0.0  \n",
       "2016-0133-IND      0.0  \n",
       "2017-9999-AUS      0.0  \n",
       "2017-0072-AUS  20000.0  \n",
       "2018-0226-JPN      0.0  \n",
       "2018-0256-PRK      0.0  \n",
       "2019-0366-BEL      0.0  \n",
       "2019-0366-FRA      0.0  \n",
       "2019-0366-NLD      0.0  \n",
       "2019-0366-DEU      0.0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heat[['Magnitude', 'Scale', 'Name', 'StartDate', 'EndDate','Deaths','Damages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heat_bounds = retrieve_bounding_dates(df_heat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinStartDate</th>\n",
       "      <th>MaxEndDate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>2015-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>2017-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>2018-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>2019-07-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MinStartDate MaxEndDate\n",
       "Year                        \n",
       "2015   2015-05-20 2015-05-31\n",
       "2016   2016-04-01 2016-05-20\n",
       "2017   2017-01-30 2017-02-14\n",
       "2018   2018-07-01 2018-08-03\n",
       "2019   2019-07-19 2019-07-27"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heat_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heat_2020 = get_df_disaster(df_emdat, HEAT_WAVES_2020, HEAT_WAVES_2020_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heat_2020_bounds = retrieve_bounding_dates(df_heat_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinStartDate</th>\n",
       "      <th>MaxEndDate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MinStartDate MaxEndDate\n",
       "Year                        \n",
       "2019   2019-09-01 2020-02-01"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heat_2020_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_storm = get_df_disaster(df_emdat, STORMS, STORMS_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Name</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Damages</th>\n",
       "      <th>Injured</th>\n",
       "      <th>TotalAffected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dis No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-0470-MEX</th>\n",
       "      <td>345.0</td>\n",
       "      <td>Kph</td>\n",
       "      <td>Hurricane Patricia</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>462000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-0041-FJI</th>\n",
       "      <td>325.0</td>\n",
       "      <td>Kph</td>\n",
       "      <td>Cyclone Winston</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>540558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-0362-USA</th>\n",
       "      <td>215.0</td>\n",
       "      <td>Kph</td>\n",
       "      <td>Hurricane Harvey</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>106.0</td>\n",
       "      <td>125000000.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>582024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-0341-CHN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Kph</td>\n",
       "      <td>Typhoon Mangkut (Ompong)</td>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1990000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-0342-USA</th>\n",
       "      <td>240.0</td>\n",
       "      <td>Kph</td>\n",
       "      <td>Hurricane Florence</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-0341-PHL</th>\n",
       "      <td>240.0</td>\n",
       "      <td>Kph</td>\n",
       "      <td>Typhoon Mangkut (Ompong)</td>\n",
       "      <td>2018-09-16</td>\n",
       "      <td>2018-09-16</td>\n",
       "      <td>127.0</td>\n",
       "      <td>628000.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>3800138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-0341-HKG</th>\n",
       "      <td>240.0</td>\n",
       "      <td>Kph</td>\n",
       "      <td>Typhoon Mangkut (Ompong)</td>\n",
       "      <td>2018-09-17</td>\n",
       "      <td>2018-09-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930000.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-0492-JPN</th>\n",
       "      <td>160.0</td>\n",
       "      <td>Kph</td>\n",
       "      <td>Tropical cylone 'Hagibis'</td>\n",
       "      <td>2019-10-12</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>99.0</td>\n",
       "      <td>17000000.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>390470.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Magnitude Scale                       Name  StartDate  \\\n",
       "Dis No                                                                 \n",
       "2015-0470-MEX      345.0   Kph         Hurricane Patricia 2015-10-22   \n",
       "2016-0041-FJI      325.0   Kph            Cyclone Winston 2016-02-20   \n",
       "2017-0362-USA      215.0   Kph           Hurricane Harvey 2017-08-25   \n",
       "2018-0341-CHN        0.0   Kph   Typhoon Mangkut (Ompong) 2018-09-10   \n",
       "2018-0342-USA      240.0   Kph         Hurricane Florence 2018-09-12   \n",
       "2018-0341-PHL      240.0   Kph   Typhoon Mangkut (Ompong) 2018-09-16   \n",
       "2018-0341-HKG      240.0   Kph   Typhoon Mangkut (Ompong) 2018-09-17   \n",
       "2019-0492-JPN      160.0   Kph  Tropical cylone 'Hagibis' 2019-10-12   \n",
       "\n",
       "                 EndDate  Deaths      Damages  Injured  TotalAffected  \n",
       "Dis No                                                                 \n",
       "2015-0470-MEX 2015-10-28    14.0     462000.0      0.0        15000.0  \n",
       "2016-0041-FJI 2016-02-21    45.0    1400000.0    144.0       540558.0  \n",
       "2017-0362-USA 2017-08-29   106.0  125000000.0     24.0       582024.0  \n",
       "2018-0341-CHN 2018-09-18     6.0    1990000.0      0.0            0.0  \n",
       "2018-0342-USA 2018-09-18    53.0   24000000.0      0.0      1500000.0  \n",
       "2018-0341-PHL 2018-09-16   127.0     628000.0    138.0      3800138.0  \n",
       "2018-0341-HKG 2018-09-17     0.0     930000.0    300.0          300.0  \n",
       "2019-0492-JPN 2019-10-17    99.0   17000000.0    470.0       390470.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm[['Magnitude', 'Scale', 'Name', 'StartDate', 'EndDate','Deaths', 'Damages', 'Injured','TotalAffected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_storm_bounds = retrieve_bounding_dates(df_storm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinStartDate</th>\n",
       "      <th>MaxEndDate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>2015-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>2016-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>2017-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>2018-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019-10-12</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MinStartDate MaxEndDate\n",
       "Year                        \n",
       "2015   2015-10-22 2015-10-28\n",
       "2016   2016-02-20 2016-02-21\n",
       "2017   2017-08-25 2017-08-29\n",
       "2018   2018-09-10 2018-09-18\n",
       "2019   2019-10-12 2019-10-17"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_storm_2020 = get_df_disaster(df_emdat, STORMS_2020, STORMS_2020_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Subgroup</th>\n",
       "      <th>Type</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>Subsubtype</th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Continent</th>\n",
       "      <th>...</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Injured</th>\n",
       "      <th>Affected</th>\n",
       "      <th>Homeless</th>\n",
       "      <th>TotalAffected</th>\n",
       "      <th>Damages</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dis No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-0573-PHL</th>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tropical cyclone 'Kammuri' (Tisoy)</td>\n",
       "      <td>Philippines (the)</td>\n",
       "      <td>PHL</td>\n",
       "      <td>South-Eastern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>Kph</td>\n",
       "      <td>4.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2305075.0</td>\n",
       "      <td>342165.0</td>\n",
       "      <td>2647558.0</td>\n",
       "      <td>109151.0</td>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Group        Subgroup   Type           Subtype Subsubtype  \\\n",
       "Dis No                                                                       \n",
       "2019-0573-PHL  Natural  Meteorological  Storm  Tropical cyclone        NaN   \n",
       "\n",
       "                                             Name            Country  ISO  \\\n",
       "Dis No                                                                      \n",
       "2019-0573-PHL  Tropical cyclone 'Kammuri' (Tisoy)  Philippines (the)  PHL   \n",
       "\n",
       "                           Region Continent  ... Scale  Deaths Injured  \\\n",
       "Dis No                                       ...                         \n",
       "2019-0573-PHL  South-Eastern Asia      Asia  ...   Kph     4.0   318.0   \n",
       "\n",
       "                Affected  Homeless  TotalAffected   Damages  StartDate  \\\n",
       "Dis No                                                                   \n",
       "2019-0573-PHL  2305075.0  342165.0      2647558.0  109151.0 2019-12-02   \n",
       "\n",
       "                 EndDate Duration  \n",
       "Dis No                             \n",
       "2019-0573-PHL 2019-12-03        1  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_storm_2020_bounds = retrieve_bounding_dates(df_storm_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinStartDate</th>\n",
       "      <th>MaxEndDate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>2019-12-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MinStartDate MaxEndDate\n",
       "Year                        \n",
       "2019   2019-12-02 2019-12-03"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm_2020_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General tags for heat waves\n",
    "heat_tags = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([dD]egrees)\\b',\n",
    "        r'\\b([fF]ahrenheit)\\b',\n",
    "        r'\\b(°[fF])\\b',\n",
    "        r'\\b(°[cC])\\b',\n",
    "        r'\\b([cC]elsius)\\b',\n",
    "        r'\\b([mM]ercury (rose|hit))\\b',\n",
    "        #r'\\b(waves?)\\b', too broad\n",
    "        r'\\b([hH]eat(ing)?)\\b',\n",
    "        r'\\b([tT]emperatures?)\\b',\n",
    "        r'\\b([hH]ot(test|ter)?)\\b',\n",
    "        r'\\b([wW]arm(er|est)?)\\b',\n",
    "        r'\\b(([eE]xtreme|[vV]olatile) [wW]eather)\\b',\n",
    "        r'\\b([hH]eatstrokes?)\\b',\n",
    "        r'\\b([hH]eatwaves?)\\b',\n",
    "        r'\\b([hH]eatstorms?)\\b',\n",
    "        r'\\b([wW]orld [mM]eteorological [oO]rganisation)\\b',\n",
    "        r'\\b(WMO)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Indian Heat Wave 2015\n",
    "heat_tags_2015 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([aA]ndhra [pP]radesh)\\b',\n",
    "        r'\\b([tT]elangana)\\b',\n",
    "        r'\\b([pP]unjab)\\b',\n",
    "        r'\\b([oO]disha)\\b',\n",
    "        r'\\b([kK]hammam)\\b',\n",
    "        r'\\b([jJ]harsuguda)\\b',\n",
    "        r'\\b([hH]yderabad)\\b',\n",
    "        r'\\b([iI]ndia [mM]eteorological [dD]epartment)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Indian Heat Wave 2016\n",
    "heat_tags_2016 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([pP]halodi)\\b',\n",
    "        r'\\b([iI]ndia [mM]eteorological [dD]epartment)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sir Ivan Fire (caused by heatwave) in Australia\n",
    "heat_tags_2017 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([bB]ureau [oF]f [mM]eteorology)\\b',\n",
    "        r'\\b(New South Wales)\\b',\n",
    "        r'\\b(Pilliga)\\b',\n",
    "        r'\\b(Talleganda)\\b',\n",
    "        r'\\b(Queensland Ambulance Service)\\b',\n",
    "        r'\\b([wW]ildfires?)\\b',\n",
    "        r'\\b([oO]range sk(y|ies))\\b',\n",
    "        r'\\b([sS]moke clouds?)\\b',\n",
    "        r'\\b(([bB]ush)?[fF]ires?)\\b',\n",
    "        r'\\b([mM]egafires?)\\b',\n",
    "        r'\\b([bB]urning forests?)\\b',\n",
    "        r'\\b(Taree)\\b',\n",
    "        r'\\b(Ivanhoe)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Japan and Korea Heat Wave\n",
    "heat_tags_2018 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([kK]umagaya)\\b',\n",
    "        r'\\b([jJ]apan [mM]eteorological [aA]gency)\\b',\n",
    "        r'\\b([sS]henyang)\\b',\n",
    "        r'\\b([tT]okyo [fF]ire [dD]epartment)\\b',\n",
    "        r'\\b([gG]angneung)\\b',\n",
    "        r'\\b([hH]ayang)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Europe Heat Wave\n",
    "heat_tags_2019 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([aA]ngleur)\\b',\n",
    "        r'\\b([bB]egijnendijk)\\b',\n",
    "        r'\\b([dD]oksany)\\b',\n",
    "        r'\\b([pP]orvoo)\\b',\n",
    "        r'\\b([mM][ée]t[ée]o [fF]rance)\\b',\n",
    "        r'\\b([gG]allargues-le-[mM]ontueux)\\b',\n",
    "        r'\\b([bB]erlin[- ][tT]empelhof)\\b',\n",
    "        r'\\b([bB]randenburg)\\b',\n",
    "        r'\\b(Lingen)\\b',\n",
    "        r'\\b([mM]eteolux)\\b',\n",
    "        r'\\b([sS]teinsel)\\b',\n",
    "        r'\\b(KNMI|knmi|[rR]oyal [dD]utch [mM]eteorological [iI]nstitute)\\b',\n",
    "        r'\\b([gG]elderland)\\b',\n",
    "        r'\\b([sS]altdal)\\b',\n",
    "        r'\\b([nN]orwegian [mM]eteorological [iI]nstitute)\\b',\n",
    "        r'\\b([zZ]aragoza)\\b',\n",
    "        r'\\b([oO]skarshamn)\\b',\n",
    "        r'\\b([sS]wedish [mM]eteorological and [hH]ydrological [iI]nstitute)\\b',\n",
    "        r'\\b([mM]eteo[sW]wiss)\\b',\n",
    "        r'\\b([cC]ambridge [uU]niversity [bB]otanic [gG]arden)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# 2019–20 Australian bushfire season\n",
    "heat_tags_2020 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([wW]ildfires?)\\b',\n",
    "        r'\\b([oO]range sk(y|ies))\\b',\n",
    "        r'\\b([sS]moke clouds?)\\b',\n",
    "        r'\\b(([bB]ush)?[fF]ires?)\\b',\n",
    "        r'\\b([mM]egafires?)\\b',\n",
    "        r'\\b([bB]urning forests?)\\b',\n",
    "        r'\\b(Black Summer)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# General tags for storms\n",
    "storm_tags = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        #r'\\b([tT]ropical [sS]torms?)\\b',\n",
    "        #r'\\b([cC]yclones?)\\b',\n",
    "        #r'\\b([tT]yphoons?)\\b',   # Maybe only include for typhoon?\n",
    "        #r'\\b([hH]urricanes?)\\b', # Maybe only include for hurricane?\n",
    "        r'\\b([wW]inds?)\\b',\n",
    "        r'\\b([gG]usts?)\\b',\n",
    "        r'\\b((one|ten|[0-9]{1,2})-minute sustain(ed)?)\\b',\n",
    "        r'\\b([mM]aximum sustained winds?)\\b',\n",
    "        r'\\b([gG]ale[- ]force)\\b',\n",
    "        r'\\b([wW]orld [mM]eteorological [oO]rganisation)\\b',\n",
    "        r'\\b(WMO)\\b']\n",
    "    }\n",
    ") \n",
    "\n",
    "# Hurricane Patricia Mexico\n",
    "storm_tags_2015 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([cC]yclones?)\\b',\n",
    "        r'\\b([hH]urricanes?)\\b',\n",
    "        r'\\b(Patricia)\\b',\n",
    "        r'\\b([tT]ropical [sS]torms?)\\b',\n",
    "        r'\\b([cC]ategory 5)\\b',\n",
    "        r'\\b([fF]lood(waters?|s|ed|ing)?)\\b',\n",
    "        r'\\b(rain(ed|s|fall)?)\\b',\n",
    "        r'\\b(NOAA)\\b',\n",
    "        r'\\b(Tehuantepec)\\b',\n",
    "        r'\\b(Jalisco)\\b',\n",
    "        r'\\b(Federal Emergency Management Agency|FEMA)\\b',\n",
    "        r'\\b(National Hurricane Center|NHC)\\b',\n",
    "        r'\\b(Mexican (Red Cross|Army|Navy|Federal Police))\\b']\n",
    "    }\n",
    ") \n",
    "\n",
    "# Cyclone Winston Fiji\n",
    "storm_tags_2016 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([cC]yclones?)\\b',\n",
    "        r'\\b(Winston)\\b',\n",
    "        r'\\b([cC]ategory 5)\\b',\n",
    "        r'\\b(Vanua Balavu)\\b',\n",
    "        r'\\b(Viti Levu)\\b',\n",
    "        r'\\b(Fiji)\\b',\n",
    "        r'\\b([jJ]oint [tT]yphoon [wW]arning [cC]enter)\\b',\n",
    "        r'\\b(Rakiraki District)\\b',\n",
    "        r'\\b(FMS)\\b',\n",
    "        r'\\b(Fijian Red Cross)\\b']\n",
    "    }\n",
    ") \n",
    "\n",
    "# Hurricane Harvey USA\n",
    "storm_tags_2017 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([hH]urricanes?)\\b',\n",
    "        r'\\b(Harvey)\\b',\n",
    "        r'\\b([tT]ropical [sS]torms?)\\b',\n",
    "        r'\\b([cC]ategory 4)\\b',\n",
    "        r'\\b([fF]lood(waters?|s|ed|ing)?)\\b',\n",
    "        r'\\b(rain(ed|s|fall)?)\\b',\n",
    "        r'\\b(NOAA)\\b',\n",
    "        r'\\b([sS]an [jJ]os[ée] [iI]sland)\\b',\n",
    "        r'\\b(Holiday Beach)\\b',\n",
    "        r'\\b(Federal Emergency Management Agency|FEMA)\\b',\n",
    "        r'\\b(National Hurricane Center|NHC)\\b',\n",
    "        r'\\b(H.R. ?601)\\b']\n",
    "    }\n",
    ") \n",
    "\n",
    "# Pacific Asia Typhoon Mangkhut (Ompong) and Hurricane Florence in US \n",
    "storm_tags_2018 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        # Mangkhut tags\n",
    "        r'\\b([cC]yclones?)\\b',\n",
    "        r'\\b([tT]yphoons?)\\b',\n",
    "        r'\\b([mM]angkhut)\\b',\n",
    "        r'\\b([oO]mpong)\\b',\n",
    "        r'\\b([cC]agayan)\\b',\n",
    "        r'\\b([cC]ategory 5)\\b',\n",
    "        r'\\b([nN]orthern [mM]ariana [iI]slands)\\b',\n",
    "        r'\\b([bB]aggao)\\b',\n",
    "        r'\\b([cC]agayan)\\b',\n",
    "        r'\\b([hH]ong [kK]ong [oO]bservatory)\\b',\n",
    "        r'\\b([hH]urricane [sS]ignal)\\b',\n",
    "        r'\\b([gG]uangdong)\\b',\n",
    "        r'\\b([mM]eteorological [bB]ureau)\\b',\n",
    "        r'\\b([gG]uangzhou)\\b',\n",
    "        ## Hurricane Florence tags\n",
    "        r'\\b([hH]urricanes?)\\b',\n",
    "        r'\\b(Florence)\\b',\n",
    "        r'\\b([tT]ropical [sS]torms?)\\b',\n",
    "        r'\\b([cC]ategory 4)\\b',\n",
    "        r'\\b([wW]rightsville [bB]each)\\b',\n",
    "        r'\\b([fF]lood(waters?|s|ed|ing)?)\\b',\n",
    "        r'\\b(rain(ed|s|fall)?)\\b',\n",
    "        r'\\b(NOAA)\\b',\n",
    "        r'\\b(SCEMD)\\b',\n",
    "        r'\\b(Federal Emergency Management Agency|FEMA)\\b',\n",
    "        r'\\b(National Hurricane Center|NHC)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Japan Tropical Cyclone Hagibis\n",
    "storm_tags_2019 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([cC]yclones?)\\b',\n",
    "        r'\\b([tT]yphoons?)\\b',\n",
    "        r'\\b([rR]eiwa 1)\\b',\n",
    "        r'\\b([hH]agibis)\\b',\n",
    "        r'\\b([cC]ategory 5)\\b',\n",
    "        #r'\\b([jJ]apan)\\b', too broad\n",
    "        r'\\b([fF]lood(waters?|s|ed|ing)?)\\b',\n",
    "        r'\\b([lL]andslides?)\\b',\n",
    "        r'\\b(rain(ed|s|fall)?)\\b',\n",
    "        r'\\b([cC]hikuma [rR]iver)\\b',\n",
    "        r'\\b([uU]eda)\\b',\n",
    "        r'\\b([hH]imawari)\\b',\n",
    "        r'\\b([nN]agano)\\b',\n",
    "        r'\\b([iI]chihara)\\b',\n",
    "        r'\\b([sS]hinkansen)\\b',\n",
    "        r'\\b([fF]ukushima)\\b',\n",
    "        r'\\b([aA]kiyama [rR]iver)\\b',\n",
    "        r'\\b([eE]vacuat(ion|ed?)( center)?)\\b',\n",
    "        r'\\b([jJ]apan [mM]eteorological [aA]gency)\\b',\n",
    "        r'\\b([iI]zu [pP]eninsula)\\b',\n",
    "        r'\\b([sS]hizuoka)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Tropical Cyclone Kammuri\n",
    "storm_tags_2020 = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([cC]yclones?)\\b',\n",
    "        r'\\b([tT]yphoons?)\\b',\n",
    "        r'\\b([kK]ammuri)\\b',\n",
    "        r'\\b([tT]isoy)\\b',\n",
    "        r'\\b(Mariana Islands)\\b',\n",
    "        r'\\b([cC]ategory 4)\\b',\n",
    "        r'\\b(Philippine Area of Responsibility)\\b',\n",
    "        r'\\b(Bicol Region)\\b',\n",
    "        r'\\b(PAGASA)\\b',\n",
    "        r'\\b([fF]lood(waters?|s|ed|ing)?)\\b',\n",
    "        r'\\b(rain(ed|s|fall)?)\\b']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Cyclone Amphan India Bangladesh\n",
    "storm_tags_2020_unused = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([cC]yclones?)\\b',\n",
    "        r'\\b(Amphan)\\b',\n",
    "        r'\\b([cC]ategory 5)\\b',\n",
    "        r'\\b(West Bengal)\\b',\n",
    "        r'\\b(Kerala)\\b',\n",
    "        r'\\b(Satkhira)\\b',\n",
    "        r'\\b([jJ]oint [tT]yphoon [wW]arning [cC]enter)\\b',\n",
    "        r'\\b(North Indian Ocean)\\b',\n",
    "        r'\\b(Indian (Air Force|Navy))\\b',\n",
    "        r'\\b(National Disaster Response Force|NDRF)\\b',\n",
    "        r'\\b(Bangladesh (Air Force|Army|Armed Forces|Meteorological Department))\\b',\n",
    "        r'\\b(Sri Lanka (Air Force|Navy))\\b',\n",
    "        r'\\b([fF]lood(waters?|s|ed|ing)?)\\b',\n",
    "        r'\\b([lL]andslides?)\\b',\n",
    "        r'\\b(rain(ed|s|fall)?)\\b']\n",
    "    }\n",
    ") \n",
    "\n",
    "climate_tags = pd.DataFrame(\n",
    "    {'tags': [\n",
    "        r'\\b([cC]limate ([iI]mpact|[cC]hange|[cC]risis|[mM]odel|[eE]mergency))\\b',\n",
    "        r'\\b([gG]lobal [wW]arming)\\b',\n",
    "        r'\\b([gG]reenhouse)\\b']\n",
    "    }\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2019\n",
    "data_path = 'data/quotes-'+str(YEAR)+'.json.bz2'\n",
    "compression = 'bz2'\n",
    "chunksize = 100000\n",
    "disaster_df = df_storm\n",
    "disaster_type = 'storm'\n",
    "regex_pattern = generate_regex_from_year_and_type(YEAR, disaster_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_df_bounds = retrieve_bounding_dates(disaster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_YEAR, end_YEAR = disaster_df_bounds.loc[YEAR].MinStartDate, disaster_df_bounds.loc[YEAR].MaxEndDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_YEAR, upper_YEAR = compute_date_bounds(start_YEAR, end_YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2019-09-21', '2019-11-07')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_YEAR, upper_YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_result = process_quotes(data_path,lower_YEAR,upper_YEAR,YEAR,regex_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df_to_disk(df_concat_result, disaster_type, YEAR, compression=compression, file_type='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing it like this also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = pd.read_json('data/quotes-'+str(YEAR)+'.json.bz2', lines=True, compression='bz2', chunksize=chunksize, nrows=nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_interval_list = []\n",
    "for chunk in tqdm(quotes, total=nrows // chunksize):\n",
    "    chunk_interval = chunk[(chunk['date'] >= lower_YEAR) & (chunk['date'] <= upper_YEAR)]\n",
    "    chunk_interval_list.append(chunk_interval[chunk_interval['quotation'].str.contains(regex_pattern)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunk_interval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interval_storm = pd.concat(chunk_interval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_interval_storm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To remove unwanted quotes based on regex pattern:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote='it makes no sense to keep on letting millions of illegal or legal immigrants flood into the United States, and to keep the tens of millions that are already here.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote='check out the huge flood migrant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "word = quote\n",
    "regex_pos = re.compile(r'flood')\n",
    "regex_neg = re.compile(r'legal|migrant')\n",
    "if regex_pos.search(word) and not regex_neg.search(word):\n",
    "    print(\"match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 (more efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.filter(regex='my_expression').columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bbc67402def311b96fab883d2c883a39527be9a4d3d9f29179a0d00da6a6745"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
